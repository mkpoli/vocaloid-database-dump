{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10851, 10852, 10853, 10854, 10855, 10856, 10857, 10858, 10859, 10860, 10861, 10862, 10863, 10864, 10865, 10866, 10867, 10868, 10869, 10870, 10871, 10872, 10873, 10874, 10875, 10876, 10877, 10878, 10879, 10880, 10881, 10882, 10883, 10884, 10885, 10886, 10887, 10888, 10889, 10890, 10891, 10892, 10893, 10894, 10895, 10896, 10897, 10898, 10899, 10900, 10901, 10902, 10903, 10904, 10905, 10906, 10907, 10908, 10909, 10910, 10911, 10912, 10913, 10914, 10915, 10916, 10917, 10918, 10919, 10920, 10921, 10922, 10923, 10924, 10925, 10926, 10927, 10928, 10929, 10930, 10931, 10932, 10933, 10934, 10935, 10936, 10937, 10938, 10939, 10940, 10941, 10942, 10943, 10944, 10945, 10946, 11260, 11845, 12156, 12904, 13212, 13282, 13348, 13573, 14780, 16014]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "files = list(Path('../dump').glob('*.wiki'))\n",
    "\n",
    "# Extract numeric parts from filenames and convert to a sorted list of integers\n",
    "numbers = sorted(int(f.stem) for f in files)\n",
    "\n",
    "# Find gaps in the sequence\n",
    "gaps = [n for n in range(numbers[0], numbers[-1] + 1) if n not in numbers]\n",
    "\n",
    "# Print the gaps\n",
    "\n",
    "new_gaps = [g for g in gaps if g > 10471]\n",
    "\n",
    "print(new_gaps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching the list of pages...\n",
      "Page 5933 already downloaded. Skipping.\n",
      "Page 5934 already downloaded. Skipping.\n",
      "Page 5935 already downloaded. Skipping.\n",
      "Page 5936 already downloaded. Skipping.\n",
      "Page 5937 already downloaded. Skipping.\n",
      "Page 5938 already downloaded. Skipping.\n",
      "Page 5939 already downloaded. Skipping.\n",
      "Page 5940 already downloaded. Skipping.\n",
      "Page 5941 already downloaded. Skipping.\n",
      "Page 5942 already downloaded. Skipping.\n",
      "Page 5943 already downloaded. Skipping.\n",
      "Page 5944 already downloaded. Skipping.\n",
      "Page 5945 already downloaded. Skipping.\n",
      "Page 5946 already downloaded. Skipping.\n",
      "Page 5947 already downloaded. Skipping.\n",
      "Page 5948 already downloaded. Skipping.\n",
      "Page 5949 already downloaded. Skipping.\n",
      "Page 5950 already downloaded. Skipping.\n",
      "Page 5951 already downloaded. Skipping.\n",
      "Page 5952 already downloaded. Skipping.\n",
      "Page 5953 already downloaded. Skipping.\n",
      "Page 5954 already downloaded. Skipping.\n",
      "Page 5955 already downloaded. Skipping.\n",
      "Page 5956 already downloaded. Skipping.\n",
      "Page 5957 already downloaded. Skipping.\n",
      "Page 5958 already downloaded. Skipping.\n",
      "Page 5959 already downloaded. Skipping.\n",
      "Page 5960 already downloaded. Skipping.\n",
      "Page 5961 already downloaded. Skipping.\n",
      "Page 5962 already downloaded. Skipping.\n",
      "Page 5963 already downloaded. Skipping.\n",
      "Page 5964 already downloaded. Skipping.\n",
      "Page 5965 already downloaded. Skipping.\n",
      "Page 5966 already downloaded. Skipping.\n",
      "Page 5967 already downloaded. Skipping.\n",
      "Page 5968 already downloaded. Skipping.\n",
      "Page 5969 already downloaded. Skipping.\n",
      "Page 5970 already downloaded. Skipping.\n",
      "Page 5971 already downloaded. Skipping.\n",
      "Page 5972 already downloaded. Skipping.\n",
      "Page 5973 already downloaded. Skipping.\n",
      "Page 5974 already downloaded. Skipping.\n",
      "Page 5975 already downloaded. Skipping.\n",
      "Page 5976 already downloaded. Skipping.\n",
      "Page 5977 already downloaded. Skipping.\n",
      "Page 5978 already downloaded. Skipping.\n",
      "Page 5979 already downloaded. Skipping.\n",
      "Page 5980 already downloaded. Skipping.\n",
      "Page 5981 already downloaded. Skipping.\n",
      "Page 5982 already downloaded. Skipping.\n",
      "Page 5983 already downloaded. Skipping.\n",
      "Page 5984 already downloaded. Skipping.\n",
      "Page 5985 already downloaded. Skipping.\n",
      "Page 5986 already downloaded. Skipping.\n",
      "Page 5987 already downloaded. Skipping.\n",
      "Page 5988 already downloaded. Skipping.\n",
      "Page 5989 already downloaded. Skipping.\n",
      "Page 5990 already downloaded. Skipping.\n",
      "Page 5991 already downloaded. Skipping.\n",
      "Page 5992 already downloaded. Skipping.\n",
      "Page 5993 already downloaded. Skipping.\n",
      "Page 5994 already downloaded. Skipping.\n",
      "Page 5995 already downloaded. Skipping.\n",
      "Page 5996 already downloaded. Skipping.\n",
      "Page 5997 already downloaded. Skipping.\n",
      "Page 5998 already downloaded. Skipping.\n",
      "Page 5999 already downloaded. Skipping.\n",
      "Page 6000 already downloaded. Skipping.\n",
      "Page 6001 already downloaded. Skipping.\n",
      "Page 6002 already downloaded. Skipping.\n",
      "Page 6003 already downloaded. Skipping.\n",
      "Page 6004 already downloaded. Skipping.\n",
      "Page 6005 already downloaded. Skipping.\n",
      "Page 6006 already downloaded. Skipping.\n",
      "Page 6007 already downloaded. Skipping.\n",
      "Page 6008 already downloaded. Skipping.\n",
      "Page 6009 already downloaded. Skipping.\n",
      "Page 6010 already downloaded. Skipping.\n",
      "Page 6011 already downloaded. Skipping.\n",
      "Page 6012 already downloaded. Skipping.\n",
      "Page 6013 already downloaded. Skipping.\n",
      "Page 6014 already downloaded. Skipping.\n",
      "Page 6015 already downloaded. Skipping.\n",
      "Page 6016 already downloaded. Skipping.\n",
      "Page 6017 already downloaded. Skipping.\n",
      "Page 6018 already downloaded. Skipping.\n",
      "Downloaded page 6019: ∞　INFINITIA\n",
      "Downloaded page 6020: 死桜\n",
      "Downloaded page 6021: お嬢P\n",
      "Downloaded page 6022: センチメンタル/光収容\n",
      "Downloaded page 6023: Virgin Glory\n",
      "Downloaded page 6024: 逃避的道化師\n",
      "Downloaded page 6025: Where I Am Standing\n",
      "Downloaded page 6026: Always and Forever\n",
      "Downloaded page 6027: とくP\n",
      "Downloaded page 6028: SPiCa\n",
      "Downloaded page 6029: CALL ME/ンチャP\n",
      "Downloaded page 6030: Green Apple\n",
      "Downloaded page 6031: DEBUTANTE IV\n",
      "Downloaded page 6032: @\n",
      "Page 6033 already downloaded. Skipping.\n",
      "Page 6034 already downloaded. Skipping.\n",
      "Page 6035 already downloaded. Skipping.\n",
      "Page 6036 already downloaded. Skipping.\n",
      "Page 6037 already downloaded. Skipping.\n",
      "Page 6038 already downloaded. Skipping.\n",
      "Page 6039 already downloaded. Skipping.\n",
      "Page 6040 already downloaded. Skipping.\n",
      "Page 6041 already downloaded. Skipping.\n",
      "Page 6042 already downloaded. Skipping.\n",
      "Page 6043 already downloaded. Skipping.\n",
      "Page 6044 already downloaded. Skipping.\n",
      "Page 6045 already downloaded. Skipping.\n",
      "Page 6046 already downloaded. Skipping.\n",
      "Page 6047 already downloaded. Skipping.\n",
      "Page 6048 already downloaded. Skipping.\n",
      "Page 6049 already downloaded. Skipping.\n",
      "Page 6050 already downloaded. Skipping.\n",
      "Page 6051 already downloaded. Skipping.\n",
      "Page 6052 already downloaded. Skipping.\n",
      "Page 6053 already downloaded. Skipping.\n",
      "Page 6054 already downloaded. Skipping.\n",
      "Page 6055 already downloaded. Skipping.\n",
      "Page 6056 already downloaded. Skipping.\n",
      "Page 6057 already downloaded. Skipping.\n",
      "Page 6058 already downloaded. Skipping.\n",
      "Page 6059 already downloaded. Skipping.\n",
      "Page 6060 already downloaded. Skipping.\n",
      "Page 6061 already downloaded. Skipping.\n",
      "Page 6062 already downloaded. Skipping.\n",
      "Page 6063 already downloaded. Skipping.\n",
      "Page 6064 already downloaded. Skipping.\n",
      "Page 6065 already downloaded. Skipping.\n",
      "Page 6066 already downloaded. Skipping.\n",
      "Page 6067 already downloaded. Skipping.\n",
      "Page 6068 already downloaded. Skipping.\n",
      "Page 6069 already downloaded. Skipping.\n",
      "Page 6070 already downloaded. Skipping.\n",
      "Page 6071 already downloaded. Skipping.\n",
      "Page 6072 already downloaded. Skipping.\n",
      "Page 6073 already downloaded. Skipping.\n",
      "Page 6074 already downloaded. Skipping.\n",
      "Page 6075 already downloaded. Skipping.\n",
      "Page 6076 already downloaded. Skipping.\n",
      "Page 6077 already downloaded. Skipping.\n",
      "Page 6078 already downloaded. Skipping.\n",
      "Page 6079 already downloaded. Skipping.\n",
      "Page 6080 already downloaded. Skipping.\n",
      "Page 6081 already downloaded. Skipping.\n",
      "Page 6082 already downloaded. Skipping.\n",
      "Page 6083 already downloaded. Skipping.\n",
      "Page 6084 already downloaded. Skipping.\n",
      "Page 6085 already downloaded. Skipping.\n",
      "Page 6086 already downloaded. Skipping.\n",
      "Page 6087 already downloaded. Skipping.\n",
      "Page 6088 already downloaded. Skipping.\n",
      "Page 6089 already downloaded. Skipping.\n",
      "Page 6090 already downloaded. Skipping.\n",
      "Page 6091 already downloaded. Skipping.\n",
      "Page 6092 already downloaded. Skipping.\n",
      "Page 6093 already downloaded. Skipping.\n",
      "Page 6094 already downloaded. Skipping.\n",
      "Page 6095 already downloaded. Skipping.\n",
      "Page 6096 already downloaded. Skipping.\n",
      "Page 6097 already downloaded. Skipping.\n",
      "Page 6098 already downloaded. Skipping.\n",
      "Page 6100 already downloaded. Skipping.\n",
      "Page 6101 already downloaded. Skipping.\n",
      "Page 6102 already downloaded. Skipping.\n",
      "Page 6103 already downloaded. Skipping.\n",
      "Page 6104 already downloaded. Skipping.\n",
      "Page 6105 already downloaded. Skipping.\n",
      "Page 6106 already downloaded. Skipping.\n",
      "Page 6107 already downloaded. Skipping.\n",
      "Page 6108 already downloaded. Skipping.\n",
      "Page 6109 already downloaded. Skipping.\n",
      "Page 6110 already downloaded. Skipping.\n",
      "Page 6111 already downloaded. Skipping.\n",
      "Page 6112 already downloaded. Skipping.\n",
      "Page 6113 already downloaded. Skipping.\n",
      "Page 6114 already downloaded. Skipping.\n",
      "Page 6115 already downloaded. Skipping.\n",
      "Page 6116 already downloaded. Skipping.\n",
      "Page 6117 already downloaded. Skipping.\n",
      "Page 6118 already downloaded. Skipping.\n",
      "Page 6119 already downloaded. Skipping.\n",
      "Page 6120 already downloaded. Skipping.\n",
      "Page 6121 already downloaded. Skipping.\n",
      "Page 6122 already downloaded. Skipping.\n",
      "Page 6123 already downloaded. Skipping.\n",
      "Page 6124 already downloaded. Skipping.\n",
      "Page 6125 already downloaded. Skipping.\n",
      "Page 6126 already downloaded. Skipping.\n",
      "Page 6127 already downloaded. Skipping.\n",
      "Page 6128 already downloaded. Skipping.\n",
      "Page 6129 already downloaded. Skipping.\n",
      "Page 6130 already downloaded. Skipping.\n",
      "Page 6131 already downloaded. Skipping.\n",
      "Page 6132 already downloaded. Skipping.\n",
      "Page 6133 already downloaded. Skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching the list of pages...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m page_list \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mget_list(_start\u001b[38;5;241m=\u001b[39mstart_from)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage_list\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/workspaces/vocaloid-database-dump/.venv/lib/python3.12/site-packages/atwiki/core.py:42\u001b[0m, in \u001b[0;36mAtWikiAPI.get_list\u001b[0;34m(self, tag, _start)\u001b[0m\n\u001b[1;32m     40\u001b[0m   pager \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcmd_tag\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma[href$=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?p=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m   soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_uri\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m   links \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpagelist\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, href\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m   pager \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matwiki_pagination\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m/workspaces/vocaloid-database-dump/.venv/lib/python3.12/site-packages/atwiki/core.py:110\u001b[0m, in \u001b[0;36mAtWikiAPI._request\u001b[0;34m(self, url, data)\u001b[0m\n\u001b[1;32m    108\u001b[0m sleep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_request \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sleep \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m sleep:\n\u001b[0;32m--> 110\u001b[0m   \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m content \u001b[38;5;241m=\u001b[39m urlopen(req)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_request \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "from atwiki import AtWikiAPI, AtWikiURI\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "REQUEST_INTERVAL = 8\n",
    "MAX_RETRIES = 5\n",
    "OUTPUT_DIR = Path(\"../dump\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "api = AtWikiAPI(\n",
    "    AtWikiURI('https://w.atwiki.jp/hmiku/'),\n",
    "    sleep=REQUEST_INTERVAL\n",
    ")\n",
    "\n",
    "start_at = new_gaps[0]\n",
    "start_from = math.floor(start_at / 100) - 1\n",
    "\n",
    "\n",
    "print(\"Fetching the list of pages...\")\n",
    "page_list = api.get_list(_start=start_from)\n",
    "\n",
    "for page in page_list:\n",
    "    page_id = page['id']\n",
    "    page_name = page['name']\n",
    "    filename = OUTPUT_DIR / f\"{page_id}.wiki\"\n",
    "\n",
    "    if filename.exists():\n",
    "        print(f\"Page {page_id} already downloaded. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    retries = 0\n",
    "\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            source = api.get_source(page_id)\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(source)\n",
    "            print(f\"Downloaded page {page_id}: {page_name}\")\n",
    "            break\n",
    "        except HTTPError as e:\n",
    "            # retries += 1\n",
    "            # wait_time = 480\n",
    "            print(f\"Failed to download page {page_id} (attempt {retries}): {e}\")\n",
    "            break\n",
    "            # print(f\"Waiting {wait_time} seconds before retrying...\")\n",
    "            # time.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(\"Unknown error\", e)\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        print(f\"Failed to download page {page_id} after {MAX_RETRIES} attempts. Skipping.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
